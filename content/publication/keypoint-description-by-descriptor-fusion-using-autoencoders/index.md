---
title: Keypoint Description by Descriptor Fusion Using Autoencoders
publication_types:
  - "1"
authors:
  - Dai
  - Zhuang and Huang
  - Xinghong and Chen
  - Weinan and Chen
  - Chuangbing and He
  - Li and Wen
  - Shuhuan and Zhang
  - Hong
doi: 10.1109/ICRA40945.2020.9197205
abstract: Keypoint matching is an important operation in computer vision and its
  applications such as visual simultaneous localization and mapping (SLAM) in
  robotics. This matching operation heavily depends on the descriptors of the
  keypoints, and it must be performed reliably when images undergo conditional
  changes such as those in illumination and viewpoint. In this paper, a
  descriptor fusion model (DFM) is proposed to create a robust keypoint
  descriptor by fusing CNN-based descriptors using autoencoders. Our DFM
  architecture can be adapted to either trained or pre-trained CNN models. Based
  on the performance of existing CNN descriptors, we choose HardNet and
  DenseNet169 as representatives of trained and pre-trained descriptors. Our
  proposed DFM is evaluated on the latest benchmark datasets in computer vision
  with challenging conditional changes. The experimental results show that DFM
  is able to achieve state-of-the-art performance, with the mean mAP that is
  6.45% and 6.53% higher than HardNet and DenseNet169, respectively.
draft: false
featured: false
image:
  filename: featured
  focal_point: Smart
  preview_only: false
date: 2021-05-01T05:45:10.571Z
---
